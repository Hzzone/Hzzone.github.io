<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title></title>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="../static/css/github-markdown.css" type="text/css">
    <link rel="stylesheet" href="../static/css/site.css" type="text/css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/xcode.min.css">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script type="text/javascript" src="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      jax: ["input/TeX", "output/PreviewHTML"],
    }
  });
</script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
</head>
<body >
    <div class="container">
        <div class="homepage">
            <a href="/">主页</a>
        </div>
        <div class="markdown-body " id="content">
            <h2 id=pca-主成分分析推导及-python-实现>PCA 主成分分析推导及 Python 实现</h2>
<p>此证明推导来源于 Deep Learning 这本书，和原书不同的在于:</p>
<ul>
<li>我证明了当 $l&gt;1$ 时的普遍情况下的目标函数。</li>
<li>原书提出使用归纳法证明 <strong>$D$ 应为 $X^TX$ 前 $l$ 个最大特征值对应的特征向量</strong> (并未证明)，在此我使用迹与特征值的性质求证最后的误差为 $\sum^l_{i=1}\lambda_i$，其中 $\lambda_i$ 为 $X^TX$ 的特征值。</li>
</ul>
<h3 id=推导>推导</h3>
<div align="center">
    <img src="pca/IMG_0040.JPG">
</div>

<div align="center">
    <img src="pca/IMG_0041.JPG">
</div>

<div align="center">
    <img src="pca/IMG_0042.JPG">
</div>

<div align="center">
    <img src="pca/IMG_0043.JPG">
</div>

<h3 id=python-实现>Python 实现</h3>
<p>下载鸢尾花数据集:</p>
<pre><code class="shell">wget http://archive.ics.uci.edu/ml/machine-learning-databases/iris/bezdekIris.data -O iris.csv</code></pre>
<p>在此对比了自己实现的 PCA 和 sklearn 实现的 <a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">PCA</a> 之间的效果和误差。</p>
<ul>
<li><p>误差: 12.909879891741815 3.8993133189625775</p>
</li>
<li><p>效果如图:</p>
</li>
</ul>
<div align="center">
    <img src="https://tuchuang-1252747889.cosgz.myqcloud.com/2018-10-29-Figure_1.png" width="900px">
</div>

<p>PCA 实现:</p>
<pre><code class="python">import utils
import numpy as np
import matplotlib.pyplot as plt
from sklearn import decomposition

# 读取数据
iris_data, iris_label = utils.read_iris(&#39;../data/iris.csv&#39;)
iris_data -= np.mean(iris_data, axis=0)

# target: 150*4
def pca(target, l):
    # l 必须小于 n，这里 n=4;
    assert l&lt;=target.shape[1]

    # 计算 X^T*X 的特征向量和特征值
    # 参考 https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.linalg.eig.html
    eig_value, eig_vector = np.linalg.eig(np.dot(target.T, target))

    index = np.argsort(eig_value)
    eig_vector = eig_vector[index]
    # 取前 l 最大的特征值对应的特征向量
    # D: N*L
    D = eig_vector[:l, :]
    D = np.transpose(D, (1, 0))

    # 解码计算误差, frobenius norm
    # X-DD^TX
    error = np.linalg.norm(target - np.dot(np.dot(D, D.T), target.T).T)
    return np.dot(target, D), error

# 150*2
result1, self_implemented_error = pca(iris_data, 2)

f = plt.figure(figsize=(16,9))
c = [&#39;#ff0000&#39;, &#39;#ffff00&#39;, &#39;#00ff00&#39;, &#39;#00ffff&#39;]


plt.subplot(1, 2, 1)
plt.title(&#39;self-implemented PCA&#39;)
for i in [0, 1, 2]:
    plt.plot(result1[iris_label == i, 0].flatten(), result1[iris_label == i, 1].flatten(), &#39;.&#39;, c=c[i])

plt.legend([&#39;0&#39;, &#39;1&#39;, &#39;2&#39;])

plt.subplot(1, 2, 2)
plt.title(&#39;sklearn PCA&#39;)
# 150*2
model = decomposition.pca.PCA(n_components=2).fit(iris_data)
result2 = model.transform(iris_data)
pca_error = np.linalg.norm(iris_data - model.inverse_transform(result2))

for i in [0, 1, 2]:
    plt.plot(result2[iris_label==i, 0].flatten(), result2[iris_label==i, 1].flatten(), &#39;.&#39;, c=c[i])

plt.legend([&#39;0&#39;, &#39;1&#39;, &#39;2&#39;])
plt.grid()
plt.show()
print(self_implemented_error, pca_error)</code></pre>

        </div>
    </div>
</body>
</html>