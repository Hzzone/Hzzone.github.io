<!DOCTYPE html>
<html lang="en">

    <head>
        <meta charset="UTF-8">
        <title>理解反向传播和框架源码阅读</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="shortcut icon" href="https://tuchuang-1252747889.cos.ap-guangzhou.myqcloud.com/hzzoneio_favicon.ico" />
        <!--<link rel="stylesheet" type="text/css" href="css/aircloud.css">-->
        <link rel="stylesheet" type="text/css" href="/static/css/aircloud.css">
        <link rel="stylesheet" type="text/css" href="/static/css/next.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/3.0.1/github-markdown.min.css" />
        <link rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/styles/default.min.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.8/highlight.min.js"></script>
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/xcode.min.css">
        <script type="text/javascript" defer src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
        <script async src="https:////busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        <link rel="stylesheet" href="/static/css/iconfont.css">
        <script src="/static/js/iconfont.js"></script>
        <!--<link href="https://cdn.bootcss.com/font-awesome/5.8.2/css/fontawesome.min.css" rel="stylesheet">-->
        <!--<link href="https://cdn.bootcss.com/font-awesome/5.8.2/css/all.min.css" rel="stylesheet">-->
    </head>

    <body>
        <div id="progress-bar"></div>
        <div class="site-nav-toggle" id="site-nav-toggle">
            <button>
                <span class="btn-bar"></span>
                <span class="btn-bar"></span>
                <span class="btn-bar"></span>
            </button>
        </div>
        <div class="index-about">
            <i>To be talented & positive.</i>
        </div>
        <div class="index-container">
            <div class="index-left">
                <div class="nav" id="nav">
                    <div class="avatar-name">
                        <div class="avatar">
                            <img src="https://avatars2.githubusercontent.com/u/19267349"></div>
                        <div class="name">
                            <i>Zhizhong Huang</i>
                        </div>
                    </div>
                    <div class="contents" id="nav-content">
                        <ul>
                            <li style="padding-left: 10px;">
                                <a href="/">
                                    <!--<i class="fa fa-fw fa-home"></i>-->
                                    <!--<span class="iconfont icon-zhihu"></span>-->
                                    <!--<i class="iconfont icon-home"></i>-->
                                    <span>主页</span>
                                </a>
                            </li>
                            <li>
                                <a href="https://github.com/Hzzone">
                                    <i class="iconfont icon-github"></i>
                                </a>
                                <a href="https://www.zhihu.com/people/hzzone">
                                    <i class="iconfont icon-zhihu"></i>
                                </a>
                            </li>
                            <!--<li>-->
                                <!--<a href="https://github.com/Hzzone">-->
                                    <!--&lt;!&ndash;<i class="fab fa-github"></i>&ndash;&gt;-->
                                    <!--<i class="iconfont icon-github"></i>-->
                                    <!--<span>Github</span></a>-->
                            <!--</li>-->
                            <!--<li>-->
                                <!--<a href="https://www.zhihu.com/people/hzzone">-->
                                    <!--&lt;!&ndash;<i class="fa fa-fw fa-zhihu"></i>&ndash;&gt;-->
                                    <!--<i class="iconfont icon-zhihu"></i>-->
                                    <!--<span>知乎</span>-->
                                <!--</a>-->
                            <!--</li>-->
                        </ul>
                    </div>
                    <!--<div id="toc" class="toc-article toc-fixed" style="height: 823px; overflow-y: scroll;">-->
                        <!--<ol class="toc">-->
                            <!--<li class="toc-item toc-level-3 active">-->
                                <!--<a class="toc-link" href="#目前遇到的问题">-->
                                    <!--<span class="toc-text">目前遇到的问题</span></a>-->
                            <!--</li>-->
                            <!--<li class="toc-item toc-level-3">-->
                                <!--<a class="toc-link" href="#问题归纳与解决">-->
                                    <!--<span class="toc-text">问题归纳与解决</span></a>-->
                            <!--</li>-->
                            <!--<li class="toc-item toc-level-3">-->
                                <!--<a class="toc-link" href="#更多">-->
                                    <!--<span class="toc-text">更多</span></a>-->
                            <!--</li>-->
                        <!--</ol>-->
                    <!--</div>-->
                </div>
                <div class="index-about-mobile">
                    <i>To be talented & positive.</i>
                </div>
            </div>
            <div class="content-wrap">
                <!-- Main Content -->
                <div class="post-container">
  <div class="post-title">理解反向传播和框架源码阅读</div>
  <div class="post-meta">
    <span class="attr">发布于：
      <span>2018-12-01 05:12:11</span>
    </span>
    <span class="attr">标签：
      <span>cs231n</span>
      </span>
    <span class="attr">访问：
      <span id="busuanzi_value_page_pv">1368</span></span>
  </div>
    <div class="markdown-body post-content post_href">
        
        <h3>反向传播</h3>
<p>反向传播其实很简单，就是梯度下降和链式法则的结合运用。对于多层神经网络反向传播尤其容易理解。</p>
<p>首先梯度下降的基本公式如下:</p>
<p>$$W = W-lr\frac{\partial L}{\partial W}$$</p>
<p>计算损失函数关于权重的梯度，然后梯度下降法更新参数。</p>
<p>不管是卷积、池化、全连接层，假设基本公式为:</p>
<p>$$y=f(x, W, b)$$</p>
<p>$x$ 为上一层的输入，$W$、$b$ 分别是需要训练的参数，$y$ 是输出。</p>
<p>对于每一层神经网络，需要计算三个偏导，$\frac{\partial L}{W}$、$\frac{\partial L}{b}$、$\frac{\partial L}{x}$。对于多层神经网络肯定不能直接对函数进行求导，而是需要利用链式法则、以前向传播的逆序获得上一层的梯度，再乘以该层的梯度即可。</p>
<p>例如:</p>
<p>$$\frac{\partial L}{W}=\frac{\partial L}{f}\frac{\partial f}{W}$$</p>
<p>$$\frac{\partial L}{x}=\frac{\partial L}{f}\frac{\partial f}{x}$$</p>
<p>对于反向传播的上一层的梯度，应为该层的 $\frac{\partial L}{\partial x}$。</p>
<p>用一张图来解释整个神经网络更新参数的过程:</p>
<p><img src="https://tuchuang-1252747889.cosgz.myqcloud.com/2018-11-30-%E6%9C%AA%E5%91%BD%E5%90%8D.001.jpeg" alt=""></p>
<p>这张图是我自己画的，所以加个水印保护下版权。</p>
<p>所以按照 cs231n 的总结，反向传播有三个步骤:</p>
<ol>
<li>
<p>Identify intermediate functions (forward prop)</p>
</li>
<li>
<p>Compute local gradients</p>
</li>
<li>
<p>Combine with upstream error signal to get full gradient</p>
</li>
</ol>
<hr>
<ol>
<li>
<p>前向传播计算损失，保留中间变量</p>
</li>
<li>
<p>计算局部梯度</p>
</li>
<li>
<p>利用链式法则结合上一层的梯度，计算出完整的梯度</p>
</li>
</ol>
<p>最后再根据梯度更新参数。</p>
<h3>矩阵求导</h3>
<p>按照 cs231n 总结一下矩阵求导的几种情况:</p>
<ul>
<li>Scalar-by-Vector（标量关于向量求导）</li>
</ul>
<p>$$
\frac { \partial y } { \partial \mathbf { x } } = \left[ \frac { \partial y } { \partial x _ { 1 } } \quad \frac { \partial y } { \partial x _ { 2 } } \ldots \frac { \partial y } { \partial x _ { n } } \right]
$$</p>
<ul>
<li>Vector-by-Vector（向量关于向量求导）</li>
</ul>
<p>$$
\frac { \partial \mathbf { y } } { \partial \mathbf { x } } = \left[ \begin{array} { c c c c } { \frac { \partial y _ { 1 } } { \partial x _ { 1 } } } &amp; { \frac { \partial y _ { 1 } } { \partial x _ { 2 } } } &amp; { \dots } &amp; { \frac { \partial y _ { 1 } } { \partial x _ { n } } } \\ { \vdots } &amp; { \vdots } &amp; { \ddots } &amp; { \vdots } \\ { \frac { \partial y _ { m } } { \partial x _ { 1 } } } &amp; { \frac { \partial y _ { m } } { \partial x _ { 2 } } } &amp; { \cdots } &amp; { \frac { \partial y _ { m } } { \partial x _ { n } } } \end{array} \right]
$$</p>
<ul>
<li>Scalar-by-Matrix（标量关于矩阵求导）</li>
</ul>
<p>$$
\frac { \partial y } { \partial A } = \left[ \begin{array} { c c c c } { \frac { \partial y } { \partial A _ { 11 } } } &amp; { \frac { \partial y } { \partial A _ { 12 } } } &amp; { \dots } &amp; { \frac { \partial y } { \partial A _ { 1 n } } } \\ { \vdots } &amp; { \vdots } &amp; { \ddots } &amp; { \vdots } \\ { \frac { \partial y } { \partial A _ { m 1 } } } &amp; { \frac { \partial y } { \partial A _ { m 2 } } } &amp; { \cdots } &amp; { \frac { \partial y } { \partial A _ { m n } } } \end{array} \right]
$$</p>
<ul>
<li>Vector-by-Matrix（向量关于矩阵求导）</li>
</ul>
<p>$$
\frac { \partial y } { \partial A _ { i j } } = \sigma_i x_j, y=Ax
$$</p>
<p>$\sigma$ 为上一层梯度。</p>
<p>下面是 cs231n 总结的深度学习中会用到的矩阵梯度的公式。其中 $W$ 是权重，$x$ 是数据，维度满足矩阵乘法。</p>
<p><img src="https://tuchuang-1252747889.cosgz.myqcloud.com/2018-11-30-%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-12-01%20%E4%B8%8A%E5%8D%8812.58.48.png" alt=""></p>
<p>分成了两部分求 $z$ 关于权重 $W$ 和输入数据 $x$ 的偏导，$z=Wx$ 和 $z=xW$，$\sigma$ 为上一层梯度。</p>
<ul>
<li>$z=Wx$</li>
</ul>
<p>$$
\delta = \frac { \partial J } { \partial z }\\
\frac { \partial z } { \partial x } = W\\
\frac { \partial J } { \partial W } = \delta ^ { \top } x
$$</p>
<ul>
<li>$z=xW$</li>
</ul>
<p>$$
\delta = \frac { \partial J } { \partial z }\\
\frac { \partial z } { \partial x } = W ^ { \top }\\
\frac { \partial J } { \partial W } = x ^ { \top } \delta
$$</p>
<p>关于矩阵求导，在 cs231n 的 <a href="http://cs231n.stanford.edu/syllabus.html">Discussion Section Backpropagation</a> 讨论了，对于损失函数为什么输出一定要是个标量，由于 Dimension Balancing 的原则，最后求偏导一定等于变量的维度，只有这样才能更新参数。</p>
<p><img src="https://tuchuang-1252747889.cosgz.myqcloud.com/2018-12-01-%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-12-01%20%E4%B8%8B%E5%8D%881.03.02.png" alt=""></p>
<h3>框架实现</h3>
<p>Caffe 是在每一个定义的 <a href="https://github.com/BVLC/caffe/tree/master/src/caffe/layers">caffe/layers</a> 中实现一对 <code>Forward</code> 和 <code>Backward</code> 函数，分别有 GPU 版本和 CPU 版本，GPU 版本定义了其核函数。</p>
<p>以 Sigmoid 和 ReLU 为例:</p>
<ul>
<li>Sigmoid</li>
</ul>
<pre class="hljs"><code><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Dtype&gt;
<span class="hljs-keyword">void</span> SigmoidLayer&lt;Dtype&gt;::Forward_cpu(<span class="hljs-keyword">const</span> <span class="hljs-built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
    <span class="hljs-keyword">const</span> <span class="hljs-built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
  <span class="hljs-keyword">const</span> Dtype* bottom_data = bottom[<span class="hljs-number">0</span>]-&gt;cpu_data();
  Dtype* top_data = top[<span class="hljs-number">0</span>]-&gt;mutable_cpu_data();
  <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> count = bottom[<span class="hljs-number">0</span>]-&gt;count();
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; count; ++i) {
    <span class="hljs-comment">// Sigmoid 函数</span>
    top_data[i] = sigmoid(bottom_data[i]);
  }
}

<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Dtype&gt;
<span class="hljs-keyword">void</span> SigmoidLayer&lt;Dtype&gt;::Backward_cpu(<span class="hljs-keyword">const</span> <span class="hljs-built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
    <span class="hljs-keyword">const</span> <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">bool</span>&gt;&amp; propagate_down,
    <span class="hljs-keyword">const</span> <span class="hljs-built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {
  <span class="hljs-keyword">if</span> (propagate_down[<span class="hljs-number">0</span>]) {
    <span class="hljs-keyword">const</span> Dtype* top_data = top[<span class="hljs-number">0</span>]-&gt;cpu_data();
    <span class="hljs-keyword">const</span> Dtype* top_diff = top[<span class="hljs-number">0</span>]-&gt;cpu_diff();
    Dtype* bottom_diff = bottom[<span class="hljs-number">0</span>]-&gt;mutable_cpu_diff();
    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> count = bottom[<span class="hljs-number">0</span>]-&gt;count();
    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; count; ++i) {
      <span class="hljs-keyword">const</span> Dtype sigmoid_x = top_data[i];
      <span class="hljs-comment">// 上一层梯度乘以该层梯度</span>
      bottom_diff[i] = top_diff[i] * sigmoid_x * (<span class="hljs-number">1.</span> - sigmoid_x);
    }
  }
}
</code></pre>
<ul>
<li>ReLU</li>
</ul>
<pre class="hljs"><code><span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Dtype&gt;
<span class="hljs-keyword">void</span> ReLULayer&lt;Dtype&gt;::Forward_cpu(<span class="hljs-keyword">const</span> <span class="hljs-built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,
    <span class="hljs-keyword">const</span> <span class="hljs-built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top) {
  <span class="hljs-keyword">const</span> Dtype* bottom_data = bottom[<span class="hljs-number">0</span>]-&gt;cpu_data();
  Dtype* top_data = top[<span class="hljs-number">0</span>]-&gt;mutable_cpu_data();
  <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> count = bottom[<span class="hljs-number">0</span>]-&gt;count();
  <span class="hljs-comment">// 该参数表明使用 ReLU、Leaky ReLU 还是 PReLU</span>
    <span class="hljs-comment">// negative_slope=0，ReLU</span>
    <span class="hljs-comment">// negative_slope=0.01 Leaky ReLU</span>
    <span class="hljs-comment">// negative_slope=whatever PReLU</span>
  Dtype negative_slope = <span class="hljs-keyword">this</span>-&gt;layer_param_.relu_param().negative_slope();
  <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; count; ++i) {
    <span class="hljs-comment">// 实现该激活函数</span>
    top_data[i] = <span class="hljs-built_in">std</span>::max(bottom_data[i], Dtype(<span class="hljs-number">0</span>))
        + negative_slope * <span class="hljs-built_in">std</span>::min(bottom_data[i], Dtype(<span class="hljs-number">0</span>));
  }
}

<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Dtype&gt;
<span class="hljs-keyword">void</span> ReLULayer&lt;Dtype&gt;::Backward_cpu(<span class="hljs-keyword">const</span> <span class="hljs-built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; top,
    <span class="hljs-keyword">const</span> <span class="hljs-built_in">vector</span>&lt;<span class="hljs-keyword">bool</span>&gt;&amp; propagate_down,
    <span class="hljs-keyword">const</span> <span class="hljs-built_in">vector</span>&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom) {
  <span class="hljs-keyword">if</span> (propagate_down[<span class="hljs-number">0</span>]) {
    <span class="hljs-keyword">const</span> Dtype* bottom_data = bottom[<span class="hljs-number">0</span>]-&gt;cpu_data();
    <span class="hljs-keyword">const</span> Dtype* top_diff = top[<span class="hljs-number">0</span>]-&gt;cpu_diff();
    Dtype* bottom_diff = bottom[<span class="hljs-number">0</span>]-&gt;mutable_cpu_diff();
    <span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> count = bottom[<span class="hljs-number">0</span>]-&gt;count();
    Dtype negative_slope = <span class="hljs-keyword">this</span>-&gt;layer_param_.relu_param().negative_slope();
    <span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; count; ++i) {
      <span class="hljs-comment">// 计算梯度，大于零就等于 x，小于零的部分只需要乘以 negative_slope</span>
      bottom_diff[i] = top_diff[i] * ((bottom_data[i] &gt; <span class="hljs-number">0</span>)
          + negative_slope * (bottom_data[i] &lt;= <span class="hljs-number">0</span>));
    }
  }
}
</code></pre>
<p>PyTorch 是以计算图为基础的自动求导机制，我整理过 PyTorch 的自动求导机制，并实现了一个初中知识里的线性拟合。</p>
<p>一个示例:</p>
<p><img src="https://tuchuang-1252747889.cosgz.myqcloud.com/2018-11-30-%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-12-01%20%E4%B8%8A%E5%8D%881.17.47.png" alt=""></p>


  </div>
    <script>
        var posts = document.getElementsByClassName('post_href')[0].getElementsByTagName('a');
        for (var i=0; i<posts.length; i++)
            posts[i].setAttribute('target', '_blank');
    </script>
</div>

                <script data-isso="https://hzzone.me/isso"
                        src="https://hzzone.me/isso/js/embed.min.js"></script>

                <div class="comments">
                    <section id="isso-thread"></section>
                </div>
            </div>

        </div>
        <script type="text/javascript">const navToggle = document.getElementById('site-nav-toggle');
            navToggle.addEventListener('click',
            function() {
                let aboutContent = document.getElementById('nav-content');
                if (!aboutContent.classList.contains('show-block')) {
                    aboutContent.classList.add('show-block');
                    aboutContent.classList.remove('hide-block');
                } else {
                    aboutContent.classList.add('hide-block');
                    aboutContent.classList.remove('show-block');
                }
            });</script>
    <script type="text/javascript">
  window.MathJax = {
    jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    },
    CommonHTML: { linebreaks: { automatic: true } },
    "HTML-CSS": { linebreaks: { automatic: true } },
         SVG: { linebreaks: { automatic: true } }
  };
</script>
    <script>
        var domDiv = document.getElementById('progress-bar');
        //domH:可视区域的高度
        var domH = window.innerHeight || document.documentElement.clientHeight || document.body.clientHeight;
        window.addEventListener('scroll',function(){
            var pageHeight = Math.max(
             document.body.scrollHeight,
             document.documentElement.scrollHeight,
             document.body.offsetHeight,
             document.documentElement.offsetHeight,
             document.documentElement.clientHeight
            );
            domDiv.style.width = Math.round(pageYOffset/(pageHeight-domH)*100)+'%';
        },false);

    </script>
    </body>

</html>