<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <title>人脸识别常用损失函数介绍</title>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/css/bootstrap.min.css">
    <link rel="stylesheet" href="../static/css/github-markdown.css" type="text/css">
    <link rel="stylesheet" href="../static/css/site.css" type="text/css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/xcode.min.css">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
    <script type="text/javascript" src="https://cdn.staticfile.org/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      jax: ["input/TeX", "output/PreviewHTML"],
    }
  });
</script>
    <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</head>
</head>
<body >
    <div class="container">
        <div class="homepage">
            <a href="/">主页</a>
        </div>
        <div class="markdown-body " id="content">
            <h2 id=参考链接>参考链接</h2>
<ul>
<li><a href="https://blog.csdn.net/autocyz/article/details/53149760">Contrastive Loss (对比损失)</a></li>
<li><a href="https://blog.csdn.net/jcjx0315/article/details/77160273">Triplet Loss及其梯度</a></li>
<li><a href="https://blog.csdn.net/u014380165/article/details/76946339">损失函数改进之Center Loss</a></li>
<li><a href="https://blog.csdn.net/tangwei2014/article/details/46812153">如何在caffe中增加layer以及caffe中triplet loss layer的实现</a></li>
<li><a href="https://github.com/Hzzone/determination-of-identity/blob/master/About-Siamese-Network.md">Siamese Network</a></li>
<li><a href="https://github.com/BVLC/caffe/blob/master/src/caffe/layers/contrastive_loss_layer.cpp">contrastive_loss_layer.cpp</a></li>
</ul>
<p><strong>以下所有 <a href="https://hzzone.io/api/latex">公式</a> 复制链接后 base64 解码可获得 LaTex 代码</strong></p>
<p>人脸识别的损失函数都有一个公共的目标，使类间间距变大，类内间距变小，总结下来就是让误判的 loss 更大，以此使提取到的特征向量是人脸识别效果更好。</p>
<h2 id=contrastive-loss>Contrastive Loss</h2>
<p>Contrastive Loss（对比损失）我第一次接触是在 Caffe 的 Siamese Network（孪生神经网络），当时对这个网络一知半解，对这个损失函数更是只会调用 API，为此我还写过一篇文档介绍 <a href="https://github.com/Hzzone/determination-of-identity/blob/master/About-Siamese-Network.md">Siamese Network</a>。</p>
<p>Siamese Network 由两个样本组合，可以相同也可以不同，两两配对进行训练。</p>
<p>Contrastive Loss 的公式如下:</p>
<p>$$\mathcal{L}=\frac{1}{2N}\sum_{n=1}^N[yd^2+(1-y)max(margin-d,0)^2]$$</p>
<p>其中 $y$ 是真实标签（同一个人则为 1，不同的人则为 0），$d$ 是两个特征向量之间的欧式距离。
例如两个样本 $x_1$ 和 $x_2$ 经过 CNN 或者其他任何手段提取到的特征向量 $v_1$ 和 $v_2$，两者之间的欧氏距离为:</p>
<p>$$d=\sqrt{(v_1-v_2)^2}$$</p>
<p>因为 $y$ 其实只有两种情况，所以最终 $\mathcal{L}$ 可以化简为:</p>
<p>$$\mathcal{L}=\left\{\begin{aligned}d^2, &amp;&amp; y=1\\max(margin-d,0)^2, &amp;&amp; y=0\\\end{aligned}\right.$$</p>
<p>求和项暂时省略。</p>
<p>$margin$ 为预设的阈值，当 $margin-d&lt;0$ 时，$\mathcal{L}=0$。</p>
<p>由此公式可推出:</p>
<ul>
<li>当 $y=1$ 时，$d$ 越大，$\mathcal{L}$ 也就越大。</li>
<li>当 $y=0$ 时，$d$ 越小，$\mathcal{L}$ 也就越大。</li>
</ul>
<p>由此很容易理解，当提取到的特征向量误判时，$\mathcal{L}$ 越大。</p>
<p>caffe 中的 <a href="https://github.com/BVLC/caffe/blob/master/src/caffe/layers/contrastive_loss_layer.cpp">contrastive_loss_layer.cpp</a> 实现主要看 <code>Forward_cpu</code> 和 <code>Backward_cpu</code> 两个函数，其他都无关紧要。</p>
<pre><code class="C++">for (int i = 0; i &lt; bottom[0]-&gt;num(); ++i) {
    dist_sq_.mutable_cpu_data()[i] = caffe_cpu_dot(channels,
        diff_.cpu_data() + (i*channels), diff_.cpu_data() + (i*channels));
    if (static_cast&lt;int&gt;(bottom[2]-&gt;cpu_data()[i])) {  // similar pairs
        loss += dist_sq_.cpu_data()[i];
    } else {  // dissimilar pairs
        if (legacy_version) {
            loss += std::max(margin - dist_sq_.cpu_data()[i], Dtype(0.0));
        } else {
            Dtype dist = std::max&lt;Dtype&gt;(margin - sqrt(dist_sq_.cpu_data()[i]),
              Dtype(0.0));
            loss += dist*dist;
        }
    }
}</code></pre>
<p><code>caffe_cpu_dot</code> 对两个向量做内积，具体代码见 <a href="https://github.com/BVLC/caffe/blob/master/src/caffe/util/math_functions.cpp">math_functions.cpp</a>，参考 <a href="https://blog.csdn.net/langb2014/article/details/50986678">梳理caffe代码math_functions(一)</a>。<code>cpu_data()</code>返回的是一个指针。</p>
<p><code>Forward_cpu</code> 计算 $\mathcal{L}$ 和公式一样，区别在于非 legacy_version 使用的是 $margin-d^2$。</p>
<p>caffe 中的 <a href="https://github.com/BVLC/caffe/blob/master/examples/siamese/mnist_siamese_train_test.prototxt">siamese example</a> 将 margin 设为了 1。</p>
<h2 id=triplet-loss>Triplet Loss</h2>
<p>Triplet Loss 我在接触 Contrastive Loss 的时候也看过，不过当时看不懂就没有深入，后来吃过很多亏。</p>
<p>Triplet Loss 和 Contrastive Loss 在样本上的差别在于，Triplet Loss 有三个样本配成两对，一对相同和一对不同；Contrastive Loss 两两配对，可以相同也可以不同。</p>
<p>Triplet 翻译成三胞胎，可以把这个 Loss Function 叫做 Triplet Loss，除了训练样本之外，看它的公式:</p>
<p>$$\mathcal{L} = \frac{1}{2N}\sum_i^N[\lVert f(x_i^{anchor})-f(x_i^{pos}) \rVert^2_2 - \lVert f(x_i^{anchor})-f(x_i^{neg}) \rVert^2_2+\alpha]_+$$</p>
<p>Triplet Loss 将一个训练样本分成三部分，一个基准为 anchor，与 anchor 同一类的为 positive，与 anchor 不同的为 negative。</p>
<p>公式的含义为 anchor 与 positive 的欧氏距离减去 anchor 与 negative 的欧式距离，然后加上一个提前设定的 $\alpha$，具体用公式描述为:</p>
<p>$$\mathcal{L} = RELU(d(x_i^{anchor}, x_i^{pos})-d(x_i^{anchor}, x_i^{neg})+\alpha)$$</p>
<p>其中 RELU 函数是为了简化公式，和 RELU 激活函数一样:</p>
<p>$$RELU(x)=\left
\{
\begin{aligned}x, &amp;&amp; x&gt;0\\
0, &amp;&amp; x\le 0\\
\end{aligned}\right.
$$</p>
<p>求和项暂时省去。</p>
<p>如果 $d(x_i^{anchor}, x_i^{pos})$ 越大，$d(x_i^{anchor}, x_i^{neg})$ 越小，说明提取到的特征向量误判越大（很容易理解，相同的距离大，不相同的反而距离小），$\mathcal{L}$ 也就越大。</p>
<p>$d(x_i^{anchor}, x_i^{neg})$ 最后肯定要比 $d(x_i^{anchor}, x_i^{pos})$ 要大，$\mathcal{L}$ 不能为 0，所以小于零时取 0。如果直接这样最后的结果必定是 $\mathcal{L}=0$，所以预设一个 $\alpha$ 表明 anchor 和 negative 的距离与 anchor 和 positive 的距离有一个最小的间距。</p>
<p>$\alpha$ 的取值很重要，$\alpha$ 过小时，提取到的特征向量区分不明显，很快就收敛了；$\alpha$ 过大时，很难收敛。</p>
<p>caffe 没有实现 Triplet Loss，但是可以参考 <a href="https://blog.csdn.net/tangwei2014/article/details/46812153">如何在caffe中增加layer以及caffe中triplet loss layer的实现</a>。</p>
<h2 id=center-loss>Center Loss</h2>
<p><a href="https://ydwen.github.io/papers/WenECCV16.pdf">A Discriminative Feature Learning Approach for Deep Face Recognition</a></p>

        </div>
    </div>
</body>
</html>