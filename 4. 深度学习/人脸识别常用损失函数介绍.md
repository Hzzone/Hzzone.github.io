## 参考链接
* [Contrastive Loss (对比损失)](https://blog.csdn.net/autocyz/article/details/53149760)
* [Triplet Loss及其梯度](https://blog.csdn.net/jcjx0315/article/details/77160273)
* [损失函数改进之Center Loss](https://blog.csdn.net/u014380165/article/details/76946339)
* [如何在caffe中增加layer以及caffe中triplet loss layer的实现](https://blog.csdn.net/tangwei2014/article/details/46812153)
* [Siamese Network](https://github.com/Hzzone/determination-of-identity/blob/master/About-Siamese-Network.md)
* [contrastive_loss_layer.cpp](https://github.com/BVLC/caffe/blob/master/src/caffe/layers/contrastive_loss_layer.cpp)

**以下所有 [公式](https://hzzone.io/api/latex) 复制链接后 base64 解码可获得 LaTex 代码**

人脸识别的损失函数都有一个公共的目标，使类间间距变大，类内间距变小，总结下来就是让误判的 loss 更大，以此使提取到的特征向量是人脸识别效果更好。

## Contrastive Loss
Contrastive Loss（对比损失）我第一次接触是在 Caffe 的 Siamese Network（孪生神经网络），当时对这个网络一知半解，对这个损失函数更是只会调用 API，为此我还写过一篇文档介绍 [Siamese Network](https://github.com/Hzzone/determination-of-identity/blob/master/About-Siamese-Network.md)。

Siamese Network 由两个样本组合，可以相同也可以不同，两两配对进行训练。

Contrastive Loss 的公式如下:

$$\mathcal{L}=\frac{1}{2N}\sum_{n=1}^N[yd^2+(1-y)max(margin-d,0)^2]$$

其中 $y$ 是真实标签（同一个人则为 1，不同的人则为 0），$d$ 是两个特征向量之间的欧式距离。
例如两个样本 $x_1$ 和 $x_2$ 经过 CNN 或者其他任何手段提取到的特征向量 $v_1$ 和 $v_2$，两者之间的欧氏距离为:

$$d=\sqrt{(v_1-v_2)^2}$$

因为 $y$ 其实只有两种情况，所以最终 $\mathcal{L}$ 可以化简为:

$$\mathcal{L}=\left\{\begin{aligned}d^2, && y=1\\max(margin-d,0)^2, && y=0\\\end{aligned}\right.$$

求和项暂时省略。

$margin$ 为预设的阈值，当 $margin-d<0$ 时，$\mathcal{L}=0$。

由此公式可推出:
* 当 $y=1$ 时，$d$ 越大，$\mathcal{L}$ 也就越大。
* 当 $y=0$ 时，$d$ 越小，$\mathcal{L}$ 也就越大。

由此很容易理解，当提取到的特征向量误判时，$\mathcal{L}$ 越大。

caffe 中的 [contrastive_loss_layer.cpp](https://github.com/BVLC/caffe/blob/master/src/caffe/layers/contrastive_loss_layer.cpp) 实现主要看 `Forward_cpu` 和 `Backward_cpu` 两个函数，其他都无关紧要。

```C++
for (int i = 0; i < bottom[0]->num(); ++i) {
    dist_sq_.mutable_cpu_data()[i] = caffe_cpu_dot(channels,
        diff_.cpu_data() + (i*channels), diff_.cpu_data() + (i*channels));
    if (static_cast<int>(bottom[2]->cpu_data()[i])) {  // similar pairs
        loss += dist_sq_.cpu_data()[i];
    } else {  // dissimilar pairs
        if (legacy_version) {
            loss += std::max(margin - dist_sq_.cpu_data()[i], Dtype(0.0));
        } else {
            Dtype dist = std::max<Dtype>(margin - sqrt(dist_sq_.cpu_data()[i]),
              Dtype(0.0));
            loss += dist*dist;
        }
    }
}
```

`caffe_cpu_dot` 对两个向量做内积，具体代码见 [math_functions.cpp](https://github.com/BVLC/caffe/blob/master/src/caffe/util/math_functions.cpp)，参考 [梳理caffe代码math_functions(一)](https://blog.csdn.net/langb2014/article/details/50986678)。`cpu_data()`返回的是一个指针。

`Forward_cpu` 计算 $\mathcal{L}$ 和公式一样，区别在于非 legacy_version 使用的是 $margin-d^2$。

caffe 中的 [siamese example](https://github.com/BVLC/caffe/blob/master/examples/siamese/mnist_siamese_train_test.prototxt) 将 margin 设为了 1。

## Triplet Loss
Triplet Loss 我在接触 Contrastive Loss 的时候也看过，不过当时看不懂就没有深入，后来吃过很多亏。

Triplet Loss 和 Contrastive Loss 在样本上的差别在于，Triplet Loss 有三个样本配成两对，一对相同和一对不同；Contrastive Loss 两两配对，可以相同也可以不同。

Triplet 翻译成三胞胎，可以把这个 Loss Function 叫做 Triplet Loss，除了训练样本之外，看它的公式:

$$\mathcal{L} = \frac{1}{2N}\sum_i^N[\lVert f(x_i^{anchor})-f(x_i^{pos}) \rVert^2_2 - \lVert f(x_i^{anchor})-f(x_i^{neg}) \rVert^2_2+\alpha]_+$$

Triplet Loss 将一个训练样本分成三部分，一个基准为 anchor，与 anchor 同一类的为 positive，与 anchor 不同的为 negative。

公式的含义为 anchor 与 positive 的欧氏距离减去 anchor 与 negative 的欧式距离，然后加上一个提前设定的 $\alpha$，具体用公式描述为:

$$\mathcal{L} = RELU(d(x_i^{anchor}, x_i^{pos})-d(x_i^{anchor}, x_i^{neg})+\alpha)$$

其中 RELU 函数是为了简化公式，和 RELU 激活函数一样:

$$RELU(x)=\left
\{
\begin{aligned}x, && x>0\\
0, && x\le 0\\
\end{aligned}\right.
$$

求和项暂时省去。

如果 $d(x_i^{anchor}, x_i^{pos})$ 越大，$d(x_i^{anchor}, x_i^{neg})$ 越小，说明提取到的特征向量误判越大（很容易理解，相同的距离大，不相同的反而距离小），$\mathcal{L}$ 也就越大。

$d(x_i^{anchor}, x_i^{neg})$ 最后肯定要比 $d(x_i^{anchor}, x_i^{pos})$ 要大，$\mathcal{L}$ 不能为 0，所以小于零时取 0。如果直接这样最后的结果必定是 $\mathcal{L}=0$，所以预设一个 $\alpha$ 表明 anchor 和 negative 的距离与 anchor 和 positive 的距离有一个最小的间距。

$\alpha$ 的取值很重要，$\alpha$ 过小时，提取到的特征向量区分不明显，很快就收敛了；$\alpha$ 过大时，很难收敛。

caffe 没有实现 Triplet Loss，但是可以参考 [如何在caffe中增加layer以及caffe中triplet loss layer的实现](https://blog.csdn.net/tangwei2014/article/details/46812153)。

## Center Loss
[A Discriminative Feature Learning Approach for Deep Face Recognition](https://ydwen.github.io/papers/WenECCV16.pdf)

